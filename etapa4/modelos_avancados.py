# -*- coding: utf-8 -*-
"""
ETAPA 4: MODELOS AVANÃ‡ADOS
Guia Passo a Passo com Washington
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import pickle
import time
import os

print("ğŸš€ INICIANDO ETAPA 4: MODELOS AVANÃ‡ADOS")
print("=" * 50)

# ConfiguraÃ§Ãµes para melhor visualizaÃ§Ã£o
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# PASSO CRÃTICO: CARREGAR DADOS DA ETAPA 3
print("\nğŸ“ PASSO 1: CARREGANDO DADOS DA ETAPA 3")

# Vamos tentar diferentes formas de carregar
try:
    # TENTATIVA 1: Carregar do CSV da Etapa 3
    df = pd.read_csv('../dataset_preprocessado.csv')
    print("âœ… Dados carregados do dataset_preprocessado.csv")
    
    # Preparar dados como na Etapa 3
    if 'sale_id' in df.columns:
        df = df.drop(columns=['sale_id'])
    
    y = df['monthly_sales']
    X = df.drop(columns=['monthly_sales'])
    X = X.apply(pd.to_numeric, errors='coerce').fillna(0)
    
    # Recriar a mesma divisÃ£o 60/20/20
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.40, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)
    
    print(f"âœ… Dados preparados:")
    print(f"   Treino: {X_train.shape}")
    print(f"   ValidaÃ§Ã£o: {X_val.shape}")
    print(f"   Teste: {X_test.shape}")
    
except Exception as e:
    print(f"âŒ Erro ao carregar dados: {e}")
    print("\nğŸ¤” Vamos resolver isso juntos!")
    print("1. O arquivo 'dataset_preprocessado.csv' estÃ¡ na pasta anterior?")
    print("2. Se nÃ£o, qual Ã© o nome do seu arquivo de dados?")
    exit()

# FunÃ§Ã£o para calcular todas as mÃ©tricas
def calcular_metricas(y_real, y_pred, nome="Modelo"):
    r2 = r2_score(y_real, y_pred)
    rmse = np.sqrt(mean_squared_error(y_real, y_pred))
    mae = mean_absolute_error(y_real, y_pred)
    mse = mean_squared_error(y_real, y_pred)
    
    print(f"ğŸ“Š {nome}:")
    print(f"   RÂ²: {r2:.4f}")
    print(f"   RMSE: {rmse:.4f}")
    print(f"   MAE: {mae:.4f}")
    print(f"   MSE: {mse:.4f}")
    
    return {'R2': r2, 'RMSE': rmse, 'MAE': mae, 'MSE': mse}

# BASELINE da Etapa 3 (vamos usar como referÃªncia)
print("\nğŸ“ˆ BASELINE - RegressÃ£o Linear (Etapa 3)")
print("   ValidaÃ§Ã£o: RÂ² = 0.3635, RMSE = 0.8017")
baseline_metrics = {'R2': 0.3635, 'RMSE': 0.8017, 'MAE': 0.5326, 'MSE': 0.6428}
# ğŸŒ² FASE 1: RANDOM FOREST (Vamos comeÃ§ar aqui!)
def fase1_random_forest(X_train, X_val, y_train, y_val):
    print("\n" + "="*60)
    print("ğŸŒ² FASE 1: RANDOM FOREST")
    print("="*60)
    
    # 1. Modelo Base (rÃ¡pido para testar)
    print("ğŸ”§ 1. Treinando Random Forest Base...")
    rf_base = RandomForestRegressor(
        n_estimators=100,
        random_state=42,
        n_jobs=-1  # Usa todos os processadores
    )
    
    inicio = time.time()
    rf_base.fit(X_train, y_train)
    tempo_base = time.time() - inicio
    
    # 2. PrediÃ§Ãµes
    y_pred_train = rf_base.predict(X_train)
    y_pred_val = rf_base.predict(X_val)
    
    # 3. MÃ©tricas
    print("ğŸ“Š 2. Calculando mÃ©tricas...")
    metrics_train = calcular_metricas(y_train, y_pred_train, "RF Base - Treino")
    metrics_val = calcular_metricas(y_val, y_pred_val, "RF Base - ValidaÃ§Ã£o")
    
    print(f"â±ï¸  3. Tempo de treino: {tempo_base:.2f} segundos")
    
    # 4. ComparaÃ§Ã£o com Baseline
    melhoria_r2 = metrics_val['R2'] - baseline_metrics['R2']
    melhoria_rmse = baseline_metrics['RMSE'] - metrics_val['RMSE']
    
    print(f"ğŸ“ˆ 4. ComparaÃ§Ã£o com Baseline:")
    print(f"    Melhoria no RÂ²: {melhoria_r2:+.4f}")
    print(f"    Melhoria no RMSE: {melhoria_rmse:+.4f}")
    
    if melhoria_r2 > 0:
        print("ğŸ‰ âœ… Random Forest SUPEROU o baseline!")
    else:
        print("âš ï¸  Random Forest nÃ£o superou o baseline (vamos otimizar!)")
    
    return rf_base, metrics_val

# EXECUTAR FASE 1
print("\nğŸš€ EXECUTANDO RANDOM FOREST...")
rf_model, rf_metrics = fase1_random_forest(X_train, X_val, y_train, y_val)

# Salvar o modelo
with open('random_forest_base.pkl', 'wb') as f:
    pickle.dump(rf_model, f)
print("ğŸ’¾ Modelo Random Forest salvo como 'random_forest_base.pkl'")
# ğŸ¯ FASE 2: OTIMIZAR RANDOM FOREST (CORRIGIR OVERFITTING)
def fase2_otimizacao_rf(X_train, X_val, y_train, y_val):
    print("\n" + "="*60)
    print("ğŸ¯ FASE 2: OTIMIZANDO RANDOM FOREST")
    print("ğŸ”§ Objetivo: Reduzir overfitting")
    print("="*60)
    
    # Grade de parÃ¢metros FOCO EM REDUZIR OVERFITTING
    param_grid = {
        'n_estimators': [100, 150],      # Menos Ã¡rvores = menos complexidade
        'max_depth': [8, 10, 12],        # Limitar profundidade
        'min_samples_split': [5, 10, 15], # Exigir mais amostras para dividir
        'min_samples_leaf': [2, 4, 6],   # Exigir mais amostras nas folhas
        'max_features': ['sqrt', 0.7]    # Limitar features por Ã¡rvore
    }
    
    print("ğŸ” Procurando melhores parÃ¢metros com GridSearch...")
    print("   (Isso pode levar 2-3 minutos)")
    
    inicio = time.time()
    
    rf = RandomForestRegressor(random_state=42, n_jobs=-1)
    
    grid_search = GridSearchCV(
        rf, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    tempo_grid = time.time() - inicio
    
    print(f"âœ… Melhores parÃ¢metros: {grid_search.best_params_}")
    print(f"âœ… Melhor RÂ² na validaÃ§Ã£o cruzada: {grid_search.best_score_:.4f}")
    print(f"â±ï¸  Tempo do GridSearch: {tempo_grid:.2f} segundos")
    
    # Testar o modelo otimizado
    melhor_rf = grid_search.best_estimator_
    
    print("\nğŸ“Š COMPARAÃ‡ÃƒO: Base vs Otimizado")
    print("-" * 40)
    
    # PrediÃ§Ãµes do modelo otimizado
    y_pred_train_otimizado = melhor_rf.predict(X_train)
    y_pred_val_otimizado = melhor_rf.predict(X_val)
    
    # MÃ©tricas do modelo otimizado
    metrics_train_otimizado = calcular_metricas(y_train, y_pred_train_otimizado, "RF Otimizado - Treino")
    metrics_val_otimizado = calcular_metricas(y_val, y_pred_val_otimizado, "RF Otimizado - ValidaÃ§Ã£o")
    
    # Calcular gap (diferenÃ§a treino-validaÃ§Ã£o)
    gap_base = rf_metrics['R2'] - 0.9774  # RÂ² treino base - RÂ² validaÃ§Ã£o base
    gap_otimizado = metrics_train_otimizado['R2'] - metrics_val_otimizado['R2']
    
    print(f"\nğŸ“ˆ ANÃLISE DE OVERFITTING:")
    print(f"   Gap Treino-ValidaÃ§Ã£o (Base): {gap_base:.4f}")
    print(f"   Gap Treino-ValidaÃ§Ã£o (Otimizado): {gap_otimizado:.4f}")
    
    if gap_otimizado < gap_base:
        print("ğŸ‰ âœ… Overfitting REDUZIDO com sucesso!")
    else:
        print("âš ï¸  Overfitting ainda presente (vamos ajustar mais)")
    
    return melhor_rf, metrics_val_otimizado

# EXECUTAR FASE 2
print("\nğŸš€ INICIANDO OTIMIZAÃ‡ÃƒO DO RANDOM FOREST...")
rf_otimizado, rf_metrics_otimizado = fase2_otimizacao_rf(X_train, X_val, y_train, y_val)

# Salvar modelo otimizado
with open('random_forest_otimizado.pkl', 'wb') as f:
    pickle.dump(rf_otimizado, f)
print("ğŸ’¾ Modelo Random Forest OTMIMIZADO salvo!")

# ComparaÃ§Ã£o final
melhoria_final_r2 = rf_metrics_otimizado['R2'] - baseline_metrics['R2']
print(f"\nğŸ¯ RESULTADO FINAL RANDOM FOREST:")
print(f"   Melhoria total vs Baseline: RÂ² +{melhoria_final_r2:.4f}")
# ğŸŒŸ FASE 3: XGBOOST (POTENCIALMENTE MELHOR AINDA!)
def fase3_xgboost(X_train, X_val, y_train, y_val):
    print("\n" + "="*60)
    print("ğŸŒŸ FASE 3: XGBOOST")
    print("ğŸ¯ Objetivo: Potencialmente superar Random Forest")
    print("="*60)
    
    try:
        # 1. XGBoost Base (rÃ¡pido)
        print("ğŸ”§ 1. Treinando XGBoost Base...")
        xgb_base = XGBRegressor(
            random_state=42,
            n_jobs=-1,
            verbosity=0
        )
        
        inicio = time.time()
        xgb_base.fit(X_train, y_train)
        tempo_base = time.time() - inicio
        
        # PrediÃ§Ãµes base
        y_pred_train_base = xgb_base.predict(X_train)
        y_pred_val_base = xgb_base.predict(X_val)
        
        # MÃ©tricas base
        metrics_train_base = calcular_metricas(y_train, y_pred_train_base, "XGBoost Base - Treino")
        metrics_val_base = calcular_metricas(y_val, y_pred_val_base, "XGBoost Base - ValidaÃ§Ã£o")
        
        print(f"â±ï¸  Tempo de treino base: {tempo_base:.2f} segundos")
        
        # 2. OTIMIZAÃ‡ÃƒO XGBoost
        print("\nğŸ” 2. Otimizando XGBoost com GridSearch...")
        print("   (Pode levar 3-4 minutos)")
        
        param_grid_xgb = {
            'n_estimators': [100, 150],
            'max_depth': [4, 6, 8],           # XGBoost geralmente precisa de menos profundidade
            'learning_rate': [0.05, 0.1],     # Taxa de aprendizado menor = mais estÃ¡vel
            'subsample': [0.8, 0.9],          # Amostragem para reduzir overfitting
            'colsample_bytree': [0.8, 0.9]    # Amostragem de features
        }
        
        xgb = XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)
        
        grid_search_xgb = GridSearchCV(
            xgb, param_grid_xgb, cv=5, scoring='r2', n_jobs=-1, verbose=1
        )
        
        inicio_grid = time.time()
        grid_search_xgb.fit(X_train, y_train)
        tempo_grid_xgb = time.time() - inicio_grid
        
        print(f"âœ… Melhores parÃ¢metros XGBoost: {grid_search_xgb.best_params_}")
        print(f"âœ… Melhor RÂ² validaÃ§Ã£o cruzada: {grid_search_xgb.best_score_:.4f}")
        print(f"â±ï¸  Tempo GridSearch XGBoost: {tempo_grid_xgb:.2f} segundos")
        
        # 3. Testar modelo otimizado
        melhor_xgb = grid_search_xgb.best_estimator_
        y_pred_train_otimizado = melhor_xgb.predict(X_train)
        y_pred_val_otimizado = melhor_xgb.predict(X_val)
        
        metrics_train_otimizado = calcular_metricas(y_train, y_pred_train_otimizado, "XGBoost Otimizado - Treino")
        metrics_val_otimizado = calcular_metricas(y_val, y_pred_val_otimizado, "XGBoost Otimizado - ValidaÃ§Ã£o")
        
        # 4. COMPARAÃ‡ÃƒO XGBoost vs Random Forest
        print("\n" + "="*50)
        print("ğŸ† COMPARAÃ‡ÃƒO FINAL: XGBoost vs Random Forest")
        print("="*50)
        
        melhoria_xgb_vs_rf = metrics_val_otimizado['R2'] - rf_metrics_otimizado['R2']
        
        print(f"ğŸ“Š Random Forest Otimizado: RÂ² = {rf_metrics_otimizado['R2']:.4f}")
        print(f"ğŸ“Š XGBoost Otimizado: RÂ² = {metrics_val_otimizado['R2']:.4f}")
        print(f"ğŸ“ˆ DiferenÃ§a: {melhoria_xgb_vs_rf:+.4f}")
        
        if melhoria_xgb_vs_rf > 0:
            print("ğŸ‰ ğŸ† XGBoost Ã‰ MELHOR que Random Forest!")
        elif melhoria_xgb_vs_rf == 0:
            print("âš–ï¸  XGBoost e Random Forest EMPATARAM!")
        else:
            print("ğŸŒ² Random Forest ainda Ã© o MELHOR!")
        
        return melhor_xgb, metrics_val_otimizado
        
    except Exception as e:
        print(f"âŒ Erro no XGBoost: {e}")
        print("ğŸ’¡ Dica: Execute 'pip install xgboost' se nÃ£o tiver instalado")
        return None, None

# EXECUTAR FASE 3
print("\nğŸš€ INICIANDO XGBOOST...")
xgb_model, xgb_metrics = fase3_xgboost(X_train, X_val, y_train, y_val)

if xgb_model is not None:
    # Salvar modelo XGBoost
    with open('xgboost_otimizado.pkl', 'wb') as f:
        pickle.dump(xgb_model, f)
    print("ğŸ’¾ Modelo XGBoost OTMIMIZADO salvo!")
    
    # RESUMO FINAL DA ETAPA 4
    print("\n" + "="*70)
    print("ğŸŠ ETAPA 4 CONCLUÃDA - RESUMO FINAL")
    print("="*70)
    
    modelos_comparacao = {
        'Baseline (Linear)': baseline_metrics,
        'Random Forest': rf_metrics_otimizado,
        'XGBoost': xgb_metrics
    }
    
    for nome, metricas in modelos_comparacao.items():
        print(f"ğŸ“Š {nome}:")
        print(f"   RÂ²: {metricas['R2']:.4f}")
        print(f"   RMSE: {metricas['RMSE']:.4f}")
        print(f"   MAE: {metricas['MAE']:.4f}")
        print()
    
    # Identificar melhor modelo
    melhor_r2 = max(metricas['R2'] for metricas in modelos_comparacao.values())
    melhor_modelo = [nome for nome, metricas in modelos_comparacao.items() if metricas['R2'] == melhor_r2][0]
    
    print(f"ğŸ† MELHOR MODELO: {melhor_modelo} (RÂ² = {melhor_r2:.4f})")
    print("ğŸ¯ PrÃ³xima etapa: Testar no conjunto de TESTE FINAL!")
    # ğŸ¯ FASE 4: TESTE FINAL NO CONJUNTO DE TESTE
def fase4_teste_final(melhor_modelo, X_test, y_test, nome_modelo="Melhor Modelo"):
    print("\n" + "="*60)
    print("ğŸ¯ FASE 4: TESTE FINAL - CONJUNTO DE TESTE")
    print(f"ğŸ“Š Testando: {nome_modelo}")
    print("="*60)
    
    # Fazer prediÃ§Ãµes no conjunto de TESTE
    y_pred_test = melhor_modelo.predict(X_test)
    
    # Calcular mÃ©tricas no TESTE
    metrics_test = calcular_metricas(y_test, y_pred_test, f"{nome_modelo} - TESTE")
    
    # Comparar com validaÃ§Ã£o
    print(f"\nğŸ“ˆ COMPARAÃ‡ÃƒO ValidaÃ§Ã£o vs Teste:")
    if nome_modelo == "XGBoost":
        r2_validacao = xgb_metrics['R2']
    else:
        r2_validacao = rf_metrics_otimizado['R2']
    
    diferenca_r2 = metrics_test['R2'] - r2_validacao
    print(f"   RÂ² ValidaÃ§Ã£o: {r2_validacao:.4f}")
    print(f"   RÂ² Teste: {metrics_test['R2']:.4f}")
    print(f"   DiferenÃ§a: {diferenca_r2:+.4f}")
    
    if abs(diferenca_r2) < 0.05:
        print("âœ… âœ… MODELO GENERALIZA BEM! (diferenÃ§a < 5%)")
    else:
        print("âš ï¸  CUIDADO: PossÃ­vel overfitting (diferenÃ§a > 5%)")
    
    return metrics_test

# EXECUTAR TESTE FINAL
print("\nğŸš€ EXECUTANDO TESTE FINAL NO XGBOOST...")
teste_metrics = fase4_teste_final(xgb_model, X_test, y_test, "XGBoost")

# ğŸŠ RELATÃ“RIO FINAL COMPLETO
print("\n" + "="*70)
print("ğŸ“‹ RELATÃ“RIO FINAL - ETAPA 4 COMPLETA")
print("="*70)

print("ğŸ¯ PERFORMANCE NOS DIFERENTES CONJUNTOS:")
print(f"   XGBoost - ValidaÃ§Ã£o: RÂ² = {xgb_metrics['R2']:.4f}")
print(f"   XGBoost - Teste: RÂ² = {teste_metrics['R2']:.4f}")

# Verificar se o modelo generaliza bem
diferenca_final = abs(teste_metrics['R2'] - xgb_metrics['R2'])
if diferenca_final < 0.03:
    print("ğŸ‰ ğŸ† MODELO FINAL VALIDADO COM SUCESSO!")
    print("   O XGBoost generaliza bem para dados nÃ£o vistos")
else:
    print("âš ï¸  AVISO: O modelo pode nÃ£o generalizar tÃ£o bem")
    print("   Considere reduzir mais o overfitting")

# Salvar mÃ©tricas finais
resultados_finais = {
    'Baseline_R2': baseline_metrics['R2'],
    'RandomForest_R2': rf_metrics_otimizado['R2'], 
    'XGBoost_Validacao_R2': xgb_metrics['R2'],
    'XGBoost_Teste_R2': teste_metrics['R2'],
    'Melhor_Modelo': 'XGBoost'
}

import json
with open('resultados_finais.json', 'w') as f:
    json.dump(resultados_finais, f, indent=2)

print("\nğŸ’¾ Resultados finais salvos em 'resultados_finais.json'")

# ğŸ¨ GRÃFICO FINAL DE COMPARAÃ‡ÃƒO
print("\nğŸ“Š GERANDO GRÃFICO COMPARATIVO FINAL...")

modelos = ['Baseline', 'Random Forest', 'XGBoost']
r2_scores = [baseline_metrics['R2'], rf_metrics_otimizado['R2'], xgb_metrics['R2']]

plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, r2_scores, color=['red', 'orange', 'green'], alpha=0.7)
plt.ylabel('RÂ² Score')
plt.title('ComparaÃ§Ã£o de Performance - Todos os Modelos')
plt.ylim(0, 1)

# Adicionar valores nas barras
for bar, valor in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{valor:.3f}', ha='center', va='bottom')

plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig('comparacao_modelos_final.png', dpi=300, bbox_inches='tight')
plt.show()

print("ğŸ’¾ GrÃ¡fico salvo como 'comparacao_modelos_final.png'")

print("\n" + "ğŸŠ" * 20)
print("ğŸ¯ ETAPA 4 CONCLUÃDA COM SUCESSO!")
print("ğŸ“ˆ PRÃ“XIMA ETAPA: AnÃ¡lise de Features e Deploy")
print("ğŸŠ" * 20)
# ğŸ”§ FASE 5: CORREÃ‡ÃƒO DE OVERFITTING NO XGBOOST
def fase5_corrigir_overfitting(X_train, X_val, X_test, y_train, y_val, y_test):
    print("\n" + "="*70)
    print("ğŸ”§ FASE 5: CORRIGINDO OVERFITTING NO XGBOOST")
    print("ğŸ¯ Objetivo: Reduzir gap validaÃ§Ã£o-teste para < 3%")
    print("="*70)
    
    # ESTRATÃ‰GIA: ParÃ¢metros MAIS RESTRITIVOS para reduzir overfitting
    param_grid_conservador = {
        'n_estimators': [80, 100],           # Menos Ã¡rvores
        'max_depth': [3, 4],                 # Profundidade MUITO menor
        'learning_rate': [0.01, 0.05],       # Learning rate menor
        'subsample': [0.7, 0.8],             # Amostragem mais agressiva
        'colsample_bytree': [0.7, 0.8],      # Menos features por Ã¡rvore
        'reg_alpha': [0.1, 0.5],             # RegularizaÃ§Ã£o L1
        'reg_lambda': [0.1, 0.5]             # RegularizaÃ§Ã£o L2
    }
    
    print("ğŸ” Buscando parÃ¢metros conservadores...")
    print("   (Foco em generalizaÃ§Ã£o, nÃ£o performance mÃ¡xima)")
    
    xgb_conservador = XGBRegressor(
        random_state=42, 
        n_jobs=-1, 
        verbosity=0
    )
    
    grid_search_conservador = GridSearchCV(
        xgb_conservador, 
        param_grid_conservador, 
        cv=5, 
        scoring='r2', 
        n_jobs=-1, 
        verbose=1
    )
    
    inicio = time.time()
    grid_search_conservador.fit(X_train, y_train)
    tempo = time.time() - inicio
    
    melhor_xgb_conservador = grid_search_conservador.best_estimator_
    print(f"âœ… Melhores parÃ¢metros conservadores: {grid_search_conservador.best_params_}")
    print(f"âœ… Melhor RÂ² validaÃ§Ã£o cruzada: {grid_search_conservador.best_score_:.4f}")
    print(f"â±ï¸  Tempo: {tempo:.2f} segundos")
    
    # TESTAR MODELO CONSERVADOR
    print("\nğŸ“Š TESTANDO MODELO CONSERVADOR:")
    
    # Treino
    y_pred_train_cons = melhor_xgb_conservador.predict(X_train)
    metrics_train_cons = calcular_metricas(y_train, y_pred_train_cons, "XGBoost Conservador - Treino")
    
    # ValidaÃ§Ã£o
    y_pred_val_cons = melhor_xgb_conservador.predict(X_val)
    metrics_val_cons = calcular_metricas(y_val, y_pred_val_cons, "XGBoost Conservador - ValidaÃ§Ã£o")
    
    # Teste
    y_pred_test_cons = melhor_xgb_conservador.predict(X_test)
    metrics_test_cons = calcular_metricas(y_test, y_pred_test_cons, "XGBoost Conservador - Teste")
    
    # ANÃLISE DE MELHORIA
    gap_original = 0.9102 - 0.8125  # 0.0977
    gap_conservador = metrics_val_cons['R2'] - metrics_test_cons['R2']
    
    print(f"\nğŸ“ˆ COMPARAÃ‡ÃƒO DE OVERFITTING:")
    print(f"   Gap Original (Val-Test): {gap_original:.4f}")
    print(f"   Gap Conservador (Val-Test): {gap_conservador:.4f}")
    print(f"   Melhoria: {gap_original - gap_conservador:.4f}")
    
    if gap_conservador < 0.03:
        print("ğŸ‰ âœ… OVERFITTING CORRIGIDO COM SUCESSO!")
    elif gap_conservador < gap_original:
        print("ğŸ“‰ Overfitting REDUZIDO (mas ainda presente)")
    else:
        print("âš ï¸  Overfitting NÃƒO melhorou")
    
    return melhor_xgb_conservador, metrics_val_cons, metrics_test_cons

# EXECUTAR CORREÃ‡ÃƒO DE OVERFITTING
print("\nğŸš€ INICIANDO CORREÃ‡ÃƒO DE OVERFITTING...")
xgb_conservador, val_cons, test_cons = fase5_corrigir_overfitting(
    X_train, X_val, X_test, y_train, y_val, y_test
)

# ğŸ† DECISÃƒO FINAL: QUAL MODELO USAR?
print("\n" + "="*70)
print("ğŸ† DECISÃƒO FINAL: QUAL MODELO IMPLEMENTAR?")
print("="*70)

print("ğŸ“Š XGBoost ORIGINAL (Overfitting):")
print(f"   RÂ² ValidaÃ§Ã£o: 0.9102 | RÂ² Teste: 0.8125 | Gap: -0.0977")

print("\nğŸ“Š XGBoost CONSERVADOR (GeneralizaÃ§Ã£o):")
print(f"   RÂ² ValidaÃ§Ã£o: {val_cons['R2']:.4f} | RÂ² Teste: {test_cons['R2']:.4f} | Gap: {val_cons['R2'] - test_cons['R2']:.4f}")

# Tomada de decisÃ£o
gap_conservador = val_cons['R2'] - test_cons['R2']
if gap_conservador < 0.03:
    modelo_final = xgb_conservador
    nome_modelo = "XGBoost Conservador"
    print(f"\nğŸ¯ DECISÃƒO: Usar {nome_modelo} (generaliza bem)")
else:
    modelo_final = xgb_model  # modelo original
    nome_modelo = "XGBoost Original" 
    print(f"\nğŸ¯ DECISÃƒO: Usar {nome_modelo} (melhor performance, mas com overfitting)")

# Salvar modelo final
with open('modelo_final.pkl', 'wb') as f:
    pickle.dump(modelo_final, f)

print(f"ğŸ’¾ Modelo final ({nome_modelo}) salvo como 'modelo_final.pkl'")

# ğŸ“‹ RELATÃ“RIO FINAL DA ETAPA 4
print("\n" + "="*70)
print("ğŸ“‹ RELATÃ“RIO FINAL COMPLETO - ETAPA 4")
print("="*70)

print("ğŸ¯ EVOLUÃ‡ÃƒO DOS MODELOS:")
modelos_evolucao = [
    ("Baseline (Linear)", 0.3635, 0.8017, "N/A"),
    ("Random Forest", 0.8798, 0.3484, f"{0.8798 - 0.3635:+.4f}"),
    ("XGBoost Original", 0.9102, 0.3011, f"{0.9102 - 0.3635:+.4f}"),
    (f"XGBoost Conservador", val_cons['R2'], val_cons['RMSE'], f"{val_cons['R2'] - 0.3635:+.4f}")
]

for nome, r2, rmse, melhoria in modelos_evolucao:
    print(f"   {nome:20} | RÂ²: {r2:6.4f} | RMSE: {rmse:6.4f} | Melhoria: {melhoria}")

print(f"\nğŸ† MODELO FINAL SELECIONADO: {nome_modelo}")
print(f"ğŸ“Š PERFORMANCE FINAL: RÂ² = {val_cons['R2']:.4f}")

print("\nâœ… ETAPA 4 OFICIALMENTE CONCLUÃDA!")
print("ğŸš€ PRÃ“XIMAS ETAPAS:")
print("   1. AnÃ¡lise de Feature Importance")
print("   2. Deploy do modelo")
print("   3. CriaÃ§Ã£o de API para previsÃµes")

# ğŸ¨ GRÃFICO FINAL COMPARATIVO
plt.figure(figsize=(12, 6))

# Dados para o grÃ¡fico
nomes = ['Baseline', 'Random Forest', 'XGBoost\nOriginal', 'XGBoost\nConservador']
r2_scores = [0.3635, 0.8798, 0.9102, val_cons['R2']]
cores = ['red', 'orange', 'lightgreen', 'green']

plt.subplot(1, 2, 1)
bars = plt.bar(nomes, r2_scores, color=cores, alpha=0.7)
plt.ylabel('RÂ² Score')
plt.title('ComparaÃ§Ã£o de Performance - RÂ²')
plt.ylim(0, 1)
for bar, valor in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{valor:.3f}', ha='center', va='bottom', fontsize=9)

plt.subplot(1, 2, 2)
# GrÃ¡fico de gaps
gaps = ['N/A', 'N/A', 0.0977, val_cons['R2'] - test_cons['R2']]
plt.bar(nomes[2:], gaps[2:], color=['lightgreen', 'green'], alpha=0.7)
plt.ylabel('Gap ValidaÃ§Ã£o-Teste')
plt.title('AnÃ¡lise de Overfitting')
for i, (bar, valor) in enumerate(zip(plt.gca().patches, gaps[2:])):
    if valor != 'N/A':
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                 f'{valor:.3f}', ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.savefig('analise_final_etapa4.png', dpi=300, bbox_inches='tight')
plt.show()

print("ğŸ’¾ GrÃ¡fico de anÃ¡lise final salvo!")